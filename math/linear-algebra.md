# 1. 向量

## 1. 范数和内积

**_向量的范数(norm)和内积(inner production)的实际意义?_**

```
🌟 范数表示向量的长短

🌟 内积/向量的L2范数乘积 表示两个向量的对齐程度

🌙 如果不特别声明, 范数一般指L2范数
🌙 内积等于0的两个向量相互正交(在二维平面表现为相互垂直)
```

**_向量的 L2 范数和内积如何计算?_**

$$
内积 = <\vec{u}, \vec{v}> = u_1v_1 + u_2v_2 + u_3v_3 = |\vec{U}|.|\vec{V}|.cos(\theta)
$$

$$
L2范数 = |\vec{u}|_{L2} = \sqrt{<\vec{u}, \vec{u}>} = \sqrt{u_1^2 + u_2^2 + u_3^2}
$$

**_函数和向量有什么关系?_**

```
>> 一个函数可以看作是一个无穷维度的向量(每一个x可以看作一个维度, 该维度的值为f(x))
```

$$
函数||f||的范数 = \sqrt{\int f^2 dx}
$$

$$
函数f和函数g的内积<<f, g>> = \int (f.g)  dx\\
$$

## 2. 线性变换

**_线性变换的定义?_**

![1698390429277](image/linear-algebra/1698390429277.png)

**_线性映射(linear map)和仿射(affine map)的区别?_**

```
仿射变换本质上是先对进行线性变换, 再进行平移
```

**_讲一下 Schmidt 正交化算法?_**

```
🌟算法目的: 将非正交基向量集合转为正交单位基向量集合

🌟算法思想: 递归算法, 向量A减去A在正交集合的每个向量方向上的分量后, 再单位化, 最后加入正交集合
```

## 3. 叉积

**_叉积在三维空间中的实际含义?_**

```
两个向量的叉积:
🌟 方向 = 垂直于这两个向量组成的平面, 遵循右手法则

🌟 长度 = 两个向量围成的四边形的面积
```

**_如何快速记忆一个三维向量的叉积公式?_**

```
使用行列式可以快速记忆叉积计算公式
```

![1699516350763](image/linear-algebra/1699516350763.png)

**_叉积在二维空间中的实际含义?_**

```
🌟 二维向量的叉积是一个标量, 大小为两个向量围成图形的面积

🌟 (x1, y1) × (x2, y2) = x1y2 - y1x2
```

**_如何求两个向量的夹角?_**

```
🌟 cos(夹角) =  向量内积/向量范数的乘积

🌟 sin(夹角) = 叉积的范数/向量范数的乘积
```

## 4. 插值

**_两个向量的插值向量有什么用?_**

```
向量a和向量b的插值向量是一个关于时间的函数: c(t), 满足:
1️⃣c(0) = a
2️⃣c(1) = b
c(t)可以作为向量a到向量b的过渡向量
```

**_向量的线性插值和角度线性插值公式?_**

$$
线性插值: \vec{c}(t) = (1-t)\vec{a} + t\vec{b}\\
角度线性插值: \vec{c}(t) = \frac{\sin[(1-t)\theta]}{\sin\theta}\vec{a} + \frac{\sin[t\theta]}{\sin\theta}\vec{b}
$$

## 5. 虚数和向量

**_为什么会有虚数单位 i?_**

```
每个一个复数对应一个二维向量, 一个复数乘i 等价于 对应的二维向量逆时针转90度
```

**_复数的乘积的几何含义是什么?_**

```
一个复数等价于一种线性变换, 一个复数w乘以复数z代表将w对应的线性变换施加到z代表的向量上, 其中:
1️⃣旋转度数 由w的辐角主值决定
2️⃣伸缩倍数由 w的模长决定
```


**_复数作为e的指数的意义是什么?_**

$$
e^z 等价于函数Exp(z) = 1 + z + \frac{z^2}{2}  + \frac{z^3}{6} + ...  + \frac{z^n}{n!} + ...
$$

**_如何证明 Euler 公式?_**

$$
\\Euler \quad Equation: e^{ix} = \cos(x) + i\sin(x)\\
将e^{ix}进行泰勒展开, 然后将展开的多项式分为两部分, 作为\cos(x), \sin(x)的泰勒展开式的项
$$

**_什么是四元组?_**

$$
一个四元组表示四维虚空间中的向量, 四元组p = a + bi + cj + dk = [a, \vec{v}]; \\
其中i^2=j^2=k^2 = ijk = -1, i/j/k之间乘法类似于向量叉乘;\\
a = 0时, p对应三维空间中的一个向量;
$$

**_四元组乘法的意义?_**
```
对三维空间中的向量进行线性变换
```

# 2. 矩阵

## 1. 矩阵和向量

**_矩阵的实际含义?_**

```
🌟 一个矩阵(m*n)可以表示m维向量到n维向量的变换

🌟 一个矩阵可以表示一个线性方程组(Ax = b)
```

## 2. 矩阵代数

**_如何求解一个矩阵向量方程式 Ax = b?_**

```
1️⃣写出增广矩阵
2️⃣进行初等行变换, 变成阶梯型矩阵
3️⃣确定自由变量, 反代求出剩余变量
```

**_初等行变换有哪三种?_**

```
🌟 交换两行
🌟 单独一行乘一个常数
🌟 A行加上B行的倍数
```

**_Ax = 0 和 Ax = b 的解集的关系是什么?_**

Ax=0

$$
齐次线性方程的解为\vec{x}_{齐次} = a\vec{u} + b\vec{v},
\\其中a,b为自由变量, \vec{u}和\vec{v}为解空间基向量
$$

Ax=b

$$
齐次线性方程的解为\vec{x}_{非齐次} = \vec{p} + \vec{x}_{齐次}, \\
\vec{p}为一个Ax = b的一个特解
$$

**_Ax = 0 有非零解的条件?_**

```
有非零解说明经过A的线性变换后所有向量围成的体积均为零, 所以A的行列式为零
```

**_逆矩阵的几何含义是什么, 如何求逆矩阵?_**

```
几何含义: 原矩阵对应的线性变换的逆变换

🌙 对增广矩阵进行初等行变换可以求逆矩阵: (A, E) => (E, A^(-1))
```

**_二维矩阵的逆矩阵如何求?_**

$$
\begin{bmatrix}
a & b\\
c & d
\end{bmatrix}^{-1} = (ad-cb)
\begin{bmatrix}
d & -b\\
-c & a
\end{bmatrix}
\\
口诀: 主交换, 反取逆, 除行列式
$$

## 3. 矩阵运算

**_为什么使用矩阵分块的方法计算矩阵乘法?_**

```
🌟对于稀疏矩阵, 分块后有大量的0矩阵, 可以加快乘法
🌟更好地利用cache
```

**_求解线性方程 Ax=b 时为什么要对系数矩阵进行 LU 分解?_**

```
进行LU分解后, 当b变换时就可以快速地计算出对应的解x

原理: 分解后原方程变为两个方程: Ux = y; Ly = b, 由于L和U为阶梯矩阵可以快速计算出y, 然后计算出x
```

## 4. 行列式

**_矩阵的行列式的几何含义是什么?_**

```
A的行列式 === A的列向量围成的体积 === 经过A对应的线性变换后向量围成的体积的变化倍率
```

**_二维/三维矩阵行列式公式是什么?_**

$$
\begin{vmatrix}
a & b\\
c & d
\end{vmatrix} = ad-bc
\\
\begin{vmatrix}
a & b & c\\
d & e & f\\
g & h & i
\end{vmatrix} = (aei+bfg+dhc) - (ceg+ahf+bdi)
$$


## 5. 矩阵的特征

**_什么是矩阵的秩, 有什么用?_**

```
>> 定义: 矩阵进行行变换后得到的阶梯型矩阵的非零行的个数

>> rank(A) 可以用于判断 方程组Ax = b的非自由变量的个数
```

**_特征向量和特征值的定义?_**

```
🌟几何定义: 特征向量在经过矩阵A对应的线性变换后向量的方向不改变(Ax = kx)

🌟直观定义: 
- 特征向量就是一个向量在经过矩阵对应的线性变换后趋向的方向
- 特征值就是趋向这个方向的速度
```

***如果一个矩阵A(n*m)的列向量线性无关会有什么性质***
```
Ax = y 一定有解, 因为Ax可以看作A的列向量的一种线性组合, 可以表示任何n维向量
```

**_如何求一个矩阵的特征值?_**

$$
\begin{align*}
&A\vec{x} = \lambda \vec{x}\\
\Rightarrow &(A-\lambda E)\vec{x} = \vec{0}\\
\Rightarrow &f(\lambda) = |A-\lambda E| = 0\\
\end{align*}
\\所以特征方程f(\lambda) = |A-\lambda E| = 0的根即为特征值
$$

**_特征分解如何加快计算矩阵幂和向量的乘积?_**

将矩阵幂化为递推公式如下:

$$
\vec{x}_{k+1} = A\vec{x}_k (k=1, 2, 3, ...)
$$

```
对于该计算, 可以将初始向量的特征向量的线性组合 x = aU + bV, 进而求出通项公式
```

**_如何判断一个矩阵是否为正定矩阵?_**

$$
如果一个矩阵A正定, 那么对应的二次型\vec{x}^T A \vec{x} > 0 (\vec{x}不为零向量)恒成立
$$

```
显然如果特征值全部>0, 则二次型>0, 则正定
```

## 6. 矩阵分解
***除了特征值分解, 还有那些分解可以加快矩阵求解?***
```
🌟奇异值分解
🌟
```